{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "78e53c7a",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/sdsc-bw/MCXAI/blob/main/explain_covertype.ipynb#scrollTo=ce81b040\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d6745d7",
   "metadata": {},
   "source": [
    "# Explain a Model of Covertype Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce81b040",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import zlib\n",
    "import requests\n",
    "from sklearn import datasets\n",
    "from sklearn.utils import Bunch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5508782e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from explainer import Explainer\n",
    "import util"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7b28aed",
   "metadata": {},
   "source": [
    "## Load and Prepare Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bd143d2",
   "metadata": {},
   "source": [
    "We use the [sklearn covertype dataset](https://scikit-learn.org/0.16/datasets/covtype.html). The code for the dataset preparation and modelling based on [this](https://colab.research.google.com/github/grochmal/daml/blob/master/nb/ol-forest-cover.ipynb#scrollTo=pQnpMme2UUxq) notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8834e928",
   "metadata": {},
   "outputs": [],
   "source": [
    "continuous = [\n",
    "    'Elevation',\n",
    "    'Aspect',\n",
    "    'Slope',\n",
    "    'HHydro',\n",
    "    'VHydro',\n",
    "    'Road',\n",
    "    'Shade_9am',\n",
    "    'Shade_Noon',\n",
    "    'Shade_3pm',\n",
    "    'Fire',\n",
    "]\n",
    "categorical = [\n",
    "    'wild=1',  # Rawah Wilderness Area\n",
    "    'wild=2',  # Neota Wilderness Area\n",
    "    'wild=3',  # Comanche Peak Wilderness Area\n",
    "    'wild=4',  # Cache la Poudre Wilderness Area\n",
    "    'soil=1','soil=2','soil=3','soil=4','soil=5','soil=6','soil=7','soil=8','soil=9','soil=10',\n",
    "    'soil=11','soil=12','soil=13','soil=14','soil=15','soil=16','soil=17','soil=18','soil=19','soil=20',\n",
    "    'soil=21','soil=22','soil=23','soil=24','soil=25','soil=26','soil=27','soil=28','soil=29','soil=30',\n",
    "    'soil=31','soil=32','soil=33','soil=34','soil=35','soil=36','soil=37','soil=38','soil=39','soil=40',\n",
    "]\n",
    "columns = continuous + categorical + ['label']\n",
    "feature_names = continuous + categorical\n",
    "target_names = ['Spruce/Fir', 'Lodgepole Pine', 'Ponderosa Pine',\n",
    "                'Cottonwood/Willow', 'Aspen', 'Douglas-fir', 'Krummholz']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9bead330",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name                                     Data Type    Measurement                       Description\n",
      "\n",
      "Elevation                               quantitative    meters                       Elevation in meters\n",
      "Aspect                                  quantitative    azimuth                      Aspect in degrees azimuth\n",
      "Slope                                   quantitative    degrees                      Slope in degrees\n",
      "Horizontal_Distance_To_Hydrology        quantitative    meters                       Horz Dist to nearest surface water features\n",
      "Vertical_Distance_To_Hydrology          quantitative    meters                       Vert Dist to nearest surface water features\n",
      "Horizontal_Distance_To_Roadways         quantitative    meters                       Horz Dist to nearest roadway\n",
      "Hillshade_9am                           quantitative    0 to 255 index               Hillshade index at 9am, summer solstice\n",
      "Hillshade_Noon                          quantitative    0 to 255 index               Hillshade index at noon, summer soltice\n",
      "Hillshade_3pm                           quantitative    0 to 255 index               Hillshade index at 3pm, summer solstice\n",
      "Horizontal_Distance_To_Fire_Points      quantitative    meters                       Horz Dist to nearest wildfire ignition points\n",
      "Wilderness_Area (4 binary columns)      qualitative     0 (absence) or 1 (presence)  Wilderness area designation\n",
      "Soil_Type (40 binary columns)           qualitative     0 (absence) or 1 (presence)  Soil Type designation\n",
      "Cover_Type (7 types)                    integer         1 to 7                       Forest Cover Type designation\n",
      "\n",
      "Forest Cover Type Classes:\t1 -- Spruce/Fir\n",
      "                                2 -- Lodgepole Pine\n",
      "                                3 -- Ponderosa Pine\n",
      "                                4 -- Cottonwood/Willow\n",
      "                                5 -- Aspen\n",
      "                                6 -- Douglas-fir\n",
      "                                7 -- Krummholz\n"
     ]
    }
   ],
   "source": [
    "# Watch out: randomizes sample sequence!\n",
    "def load_cover_type():\n",
    "    cov_dir = 'uci_cover_type'\n",
    "    data_dir = datasets.get_data_home()\n",
    "    data_path = os.path.join(data_dir, cov_dir, 'covtype.data')\n",
    "    descr_path = os.path.join(data_dir, cov_dir, 'covtype.info')\n",
    "    cov_data_gz = 'https://archive.ics.uci.edu/ml/machine-learning-databases/covtype/covtype.data.gz'\n",
    "    cov_descr = 'https://archive.ics.uci.edu/ml/machine-learning-databases/covtype/covtype.info'\n",
    "    os.makedirs(os.path.join(data_dir, cov_dir), exist_ok=True)\n",
    "    try:\n",
    "        with open(descr_path, 'r') as f:\n",
    "            descr = f.read()\n",
    "    except IOError:\n",
    "        print('Downloading file from', cov_descr, file=sys.stderr)\n",
    "        r = requests.get(cov_descr)\n",
    "        with open(descr_path, 'w') as f:\n",
    "            f.write(r.text)\n",
    "        descr = r.text\n",
    "        r.close()\n",
    "    try:\n",
    "        data = pd.read_csv(data_path, delimiter=',', names=columns)\n",
    "    except IOError:\n",
    "        print('Downloading file from', cov_data_gz, file=sys.stderr)\n",
    "        r = requests.get(cov_data_gz)\n",
    "        cov_data = zlib.decompress(r.content, wbits=16+zlib.MAX_WBITS)  # obscure but works\n",
    "        cov_data = cov_data.decode('utf8')\n",
    "        with open(data_path, 'w') as f:\n",
    "            f.write(cov_data)\n",
    "        r.close()\n",
    "        data = pd.read_csv(data_path, delimiter=',', names=columns)\n",
    "    X = data[continuous + categorical].values\n",
    "    y = data['label'].values - 1\n",
    "    return Bunch(DESCR=descr,\n",
    "                 data=X,\n",
    "                 feature_names=columns[:-1],\n",
    "                 feature_continuous=continuous,\n",
    "                 feature_categorical=categorical,\n",
    "                 target=y,\n",
    "                 target_names=target_names)\n",
    "\n",
    "\n",
    "covtype = load_cover_type()\n",
    "print(covtype.DESCR[6923:8554])\n",
    "print()\n",
    "print(covtype.DESCR[12373:12713])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e7c70cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(covtype.data, columns=covtype.feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f515cfa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we only take two classes\n",
    "X = covtype.data\n",
    "y = covtype.target\n",
    "X = X[(y == 1) | (y == 2)].copy()\n",
    "y = y[(y == 1) | (y == 2)].copy()\n",
    "y[y == 1] = 0\n",
    "y[y == 2] = 1\n",
    "df = pd.DataFrame(X, columns=covtype.feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b1dc3502",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(319055, 54)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scaling of the continous features\n",
    "sc = StandardScaler()\n",
    "X_cont = sc.fit_transform(df[covtype.feature_continuous].values)\n",
    "X_cat = df[covtype.feature_categorical].values\n",
    "X = np.c_[X_cont, X_cat]\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dc3919f",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5edee0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain, xtest, ytrain, ytest = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1196bc1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9597483209259241,\n",
       " Pipeline(steps=[('pca', PCA(n_components=10)),\n",
       "                 ('sgdclassifier',\n",
       "                  SGDClassifier(alpha=0.01, eta0=0.001, learning_rate='constant',\n",
       "                                loss='log', max_iter=500, tol=0.01))]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = make_pipeline(\n",
    "    PCA(n_components=10),\n",
    "    SGDClassifier(loss='log', penalty='l2', max_iter=500, alpha=0.01, tol=0.01,\n",
    "                  learning_rate='constant', eta0=0.001))\n",
    "param_grid = {\n",
    "    'sgdclassifier__alpha': [0.01, 0.1],\n",
    "    'sgdclassifier__tol': [0.01, 0.1],\n",
    "}\n",
    "grid = GridSearchCV(model, param_grid, cv=5)\n",
    "grid.fit(xtrain, ytrain)\n",
    "grid.best_score_, grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cf8b4bb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Aspen       0.97      0.99      0.98     56697\n",
      " Douglas-fir       0.89      0.72      0.80      7114\n",
      "\n",
      "    accuracy                           0.96     63811\n",
      "   macro avg       0.93      0.86      0.89     63811\n",
      "weighted avg       0.96      0.96      0.96     63811\n",
      "\n"
     ]
    }
   ],
   "source": [
    "names = ['Aspen', 'Douglas-fir']\n",
    "yfit = grid.best_estimator_.predict(xtest)\n",
    "print(classification_report(ytest, yfit, target_names=names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0bae3b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "cov1, cov2, ycov1, ycov2 = train_test_split(X, y, test_size=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6dff9c89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7942811755361399"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtrain1, xtest1, ytrain1, ytest1 = train_test_split(cov1, ycov1, test_size=0.2)\n",
    "model = make_pipeline(\n",
    "    PCA(n_components=10),\n",
    "    SGDClassifier(loss='log', penalty='l2', max_iter=500, alpha=0.01, tol=0.01,\n",
    "                  learning_rate='constant', eta0=0.001, warm_start=True))\n",
    "model.fit(xtrain1, ytrain1)\n",
    "yfit = model.predict(xtest1)\n",
    "f1_score(ytest1, yfit)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "321ce30b",
   "metadata": {},
   "source": [
    "## Pick a Sample for Explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fa3579a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we take a sample form the second class\n",
    "sample = X[(y == 1)][0]\n",
    "target_label = y[(y == 1)][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2f646018",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.23259517,  0.74326609,  0.34376537,  0.38476977,  0.81644083,\n",
       "       -0.92178107, -0.89442147,  1.43608755,  1.46645668, -0.43760042,\n",
       "        0.        ,  0.        ,  1.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  1.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7aff1ad7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "94099f0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.50581211, 0.49418789]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_proba([sample])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0b8d7fb",
   "metadata": {},
   "source": [
    "## Explain the Sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54896aa9",
   "metadata": {},
   "source": [
    "The explainer allows to set different hyperparameters of the agent, game and tree. First it runs the classification game (tries to make thre prediction of the target label false). If the classification is already incorrect. It skips this game. After that it runs the misclassification game (tries to make thre prediction of the target label true). \n",
    "\n",
    "The games aren't always have a solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0a6ab18c",
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = Explainer(sample, model.predict_proba, target_label, hide_value=0, max_episodes=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b91a8361",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-29 15:39:01,836 - agent - INFO - XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
      "2021-10-29 15:39:01,836 - agent - INFO - Episode:\t0\n",
      "2021-10-29 15:39:01,837 - agent - INFO - XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
      "2021-10-29 15:39:01,882 - agent - INFO - XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
      "2021-10-29 15:39:01,882 - agent - INFO - Episode:\t10\n",
      "2021-10-29 15:39:01,883 - agent - INFO - XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
      "2021-10-29 15:39:01,915 - agent - INFO - XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
      "2021-10-29 15:39:01,915 - agent - INFO - Episode:\t20\n",
      "2021-10-29 15:39:01,916 - agent - INFO - XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
      "2021-10-29 15:39:01,946 - agent - INFO - XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
      "2021-10-29 15:39:01,946 - agent - INFO - Episode:\t30\n",
      "2021-10-29 15:39:01,947 - agent - INFO - XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
      "2021-10-29 15:39:01,977 - agent - INFO - XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
      "2021-10-29 15:39:01,978 - agent - INFO - Episode:\t40\n",
      "2021-10-29 15:39:01,978 - agent - INFO - XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
      "2021-10-29 15:39:02,004 - agent - INFO - XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
      "2021-10-29 15:39:02,004 - agent - INFO - Episode:\t50\n",
      "2021-10-29 15:39:02,004 - agent - INFO - XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
      "2021-10-29 15:39:02,034 - agent - INFO - XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
      "2021-10-29 15:39:02,035 - agent - INFO - Episode:\t60\n",
      "2021-10-29 15:39:02,035 - agent - INFO - XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
      "2021-10-29 15:39:02,057 - agent - INFO - XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
      "2021-10-29 15:39:02,058 - agent - INFO - Episode:\t70\n",
      "2021-10-29 15:39:02,058 - agent - INFO - XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
      "2021-10-29 15:39:02,089 - agent - INFO - XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
      "2021-10-29 15:39:02,089 - agent - INFO - Episode:\t80\n",
      "2021-10-29 15:39:02,090 - agent - INFO - XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
      "2021-10-29 15:39:02,115 - agent - INFO - XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
      "2021-10-29 15:39:02,116 - agent - INFO - Episode:\t90\n",
      "2021-10-29 15:39:02,116 - agent - INFO - XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
      "2021-10-29 15:39:02,141 - explainer - INFO - Misclassification game finished\n"
     ]
    }
   ],
   "source": [
    "explainer.explain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f96307d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ranks_1, ranks_2 = explainer.get_explanation()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "061b0b46",
   "metadata": {},
   "source": [
    "Now the features are ranked by their importance, if the explainer was able to change the prediction (change the class with the highest probability). The lower the rank of the feature, the more important is this feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "18ba1ddb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0.])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ranks_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "551bdc4a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0.])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ranks_2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3488f18",
   "metadata": {},
   "source": [
    "For better understanding, we kann also output the feature names with their corresponding ranks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a7e763ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "ranks_1_as_list, ranks_2_as_list = explainer.get_explanation_as_list(feature_names=feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "085d12c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ranks_1_as_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d4b84212",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Shade_3pm', 1)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ranks_2_as_list"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mcxai",
   "language": "python",
   "name": "mcxai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
